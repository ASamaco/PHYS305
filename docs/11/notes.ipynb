{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Modeling I: Probability and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Why Probability and Statistics Matter in Science\n",
    "\n",
    "Any physical measurement involves some level of uncertainty or noise.\n",
    "Whether we are measuring the intensity of a star's light, the decay rate of a radioactive sample, or the temperature of the cosmic microwave background, the data we collect are never perfectly exact.\n",
    "Probability theory offers a systematic way to handle this lack of certainty.\n",
    "More specifically:\n",
    "* **Data Interpretation**:\n",
    "  We want to connect noisy observations to underlying physical models.\n",
    "  If a dataset appears to fluctuate, is that signal real, or is it random?\n",
    "  Probability gives us formal tools—like hypothesis testing or confidence intervals—to decide.\n",
    "* **Incomplete Knowledge**:\n",
    "  Even when processes are entirely deterministic at some level, we often lack complete information.\n",
    "  Probability distributions let us quantify the range of possible outcomes or parameter values.\n",
    "* **Unrepeatable Events**:\n",
    "  Fields like astronomy pose a unique challenge: many phenomena (e.g., a supernova) cannot be restarted under controlled conditions.\n",
    "  We must rely on \"fair samples\" of data from one-time observations.\n",
    "  Probability theory becomes crucial for making sense of these non-repeatable experiments.\n",
    "\n",
    "From a broad perspective, probability theory is the logic of science:\n",
    "it extends our classical (Boolean) logic into a realm where conclusions cannot be absolutely certain but can be assigned degrees of belief or confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Historical Context and Key Contributors\n",
    "\n",
    "Probability theory and its practical offshoot—statistics—did not emerge fully formed.\n",
    "Many scientists who pioneered the subject were themselves astronomers or physicists grappling with noisy measurements:\n",
    "* **Blaise Pascal & Pierre Fermat** (1650s):\n",
    "  Their work on games of chance launched the formal study of probability, initially focusing on gambling problems but laying the groundwork for more general applications.\n",
    "* **Jacob Bernoulli & Thomas Bayes** (18th century):\n",
    "  They introduced foundational ideas on how to assign and update probabilities.\n",
    "  Bayes's Theorem still underlies modern Bayesian statistics, which treats probability as \"degree of belief\" and updates those degrees using observed data.\n",
    "* **Pierre-Simon Laplace & Carl Friedrich Gauss** (late 18th/early 19th century):\n",
    "  Both were astronomers/mathematicians.\n",
    "  Gauss's work on least squares and the \"Gaussian (normal) distribution of errors\" became central to how we handle measurement noise.\n",
    "  Laplace's rediscovery of Bayesian methods brought probability firmly into the domain of scientific data interpretation.\n",
    "* **Frequentist vs. Bayesian** (20th century):\n",
    "  Mathematicians and statisticians debated how best to define, interpret, and use probabilities, especially for inference.\n",
    "  The result was a rich theoretical framework that scientists still apply daily."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ODE Integrators III: Advanced Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Adaptive Stepsize Control\n",
    "\n",
    "When we integrate ordinary differential equations (ODEs), the choice of time step $\\Delta t$ can influence the accuracy and efficiency of our numerical solutions.\n",
    "This issue becomes especially important for systems that exhibit rapid changes in time and/or chaotic behavior.\n",
    "In such cases, tiny differences in initial conditions or time step selection can lead to wildly different outcomes.\n",
    "This highlights why we must continually monitor and control numerical errors.\n",
    "\n",
    "**Adaptive step size control** provides a systematic way to handle these challenges.\n",
    "Instead of using a fixed $\\Delta t$, adaptive methods dynamically change the time step based on error estimates at each step.\n",
    "The critical idea behind adaptive step size control is to balance two competing goals:\n",
    "* **Accuracy:** Keep truncation (local) errors within a user-specified tolerance.\n",
    "* **Efficiency:** Avoid making the time step too small, which would waste computational resources.\n",
    "\n",
    "In practice, we estimate the local error of a proposed step and compare it to a tolerance that combines both absolute and relative components.\n",
    "If the error is too large, we reduce the step size.\n",
    "If it is safely below the tolerance, we may increase it.\n",
    "This approach automatically \"zooms in\" when the ODE solution changes rapidly and \"zooms out\" when the solution is smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Error Estimate\n",
    "\n",
    "To illustrate one of the simplest ways to estimate errors, consider advancing the solution from $t$ to $t + 2\\Delta t$.\n",
    "There are two ways to do this:\n",
    "1. Step the ODE system with a single step $\\Delta t' = 2\\Delta t$.\n",
    "2. Step the ODE system with two consecutive steps, each step is $\\Delta t$.\n",
    "\n",
    "For a fourth-order method (e.g., classic Runge–Kutta 4), the local truncation errors differ between these two approaches.\n",
    "Symbolically, the resulting solutions (ignoring higher-order terms) look like:\n",
    "\\begin{align}\n",
    "\\text{One step:}  \\quad x(t + 2\\Delta t) &= x_1 + (2\\Delta t)^5 \\phi + \\mathcal{O}(\\Delta t^6) + \\dots \\\\\n",
    "\\text{Two steps:} \\quad x(t + 2\\Delta t) &= x_2 +  2\\Delta t^5  \\phi + \\mathcal{O}(\\Delta t^6) + \\dots\n",
    "\\end{align}\n",
    "where $\\phi$ is some function of $t$ and $x(t)$.\n",
    "We focus on just the leading $\\Delta t^5$ terms and define\n",
    "\\begin{align}\n",
    "\\Delta = x_2 - x_1,\n",
    "\\end{align}\n",
    "to give an approximate measure of the local truncation error.\n",
    "If $\\Delta$ is \"too large,\" we should reduce $\\Delta t$.\n",
    "If $\\Delta$ is \"too small,\" we might be over-resolving the solution and can safely increase $\\Delta t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Richardson Extrapolation\n",
    "\n",
    "An interesting by-product of step doubling is Richardson extrapolation, which can yield a higher-order estimate:\n",
    "\\begin{align}\n",
    "x(t + 2\\Delta t) = x_2 + \\frac{\\Delta}{15} + \\mathcal{O}(\\Delta t^6)\n",
    "\\end{align}\n",
    "While this estimate is more accurate (fifth-order), we have no direct way to estimate or control its truncation error at that higher order.\n",
    "Therefore, it is not as convenient for adaptive step size selection as one might initially hope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Embedded Runge-Kutta Formulas: The Dormand–Prince Method\n",
    "\n",
    "Step doubling is a simple adaptive step method.\n",
    "However, it is now mostly replaced by a more efficient stepsize adjustment algorithm based on embedded Runge-Kutta formulas, originally invented by Merson and popularized in a method of Fehlberg.\n",
    "\n",
    "An interesting fact about Runge-Kutta formulas is that for orders $M$ higher than four, more than $M$ function evaluations are required.\n",
    "This accounts for the popularity of the classical fourth-order method: It seems to give the most bang for the buck. However, Fehlberg discovered a fifth-order method with six function evaluations where another combination of the six functions gives a fourth-order method.\n",
    "\n",
    "The difference between the two estimates of $y(x + \\Delta t)$ can then be used as an estimate of the truncation error to adjust the stepsize.\n",
    "Since Fehlberg's original formula, many other embedded Runge-Kutta formulas have been found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "The Dormand–Prince method is a 5th-order Runge-Kutta method with an embedded 4th-order solution.\n",
    "This pairing enables accurate error estimation, which is essential for adaptive step size control.\n",
    "The DP method is particularly favored for its robustness and efficiency, making it a staple in many numerical computing libraries, including MATLAB's ode45.\n",
    "\n",
    "The Dormand–Prince method is characterized by its specific set of coefficients, which dictate how intermediate slopes are calculated and combined to produce the final solution estimates.\n",
    "These coefficients are meticulously chosen to minimize error and optimize computational performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "The general form of a fifth-order Runge-Kutta formula is\n",
    "\\begin{align}\n",
    "k_1 &= \\Delta t f(x_n, t_n)\\\\\n",
    "k_2 &= \\Delta t f(x_n + a_{21}k_1, t_n + c_2 \\Delta t)\\\\\n",
    "\\cdots\\\\\n",
    "k_6 &= \\Delta t f(x_n + a_{61}k_1 + \\cdots + a_{65}k_5, t_n + c_6 \\Delta t)\\\\\n",
    "x_{n+1} &= x_n + b_1 k_1 + b_2 k_2 + \\cdots + b_6 k_6 + \\mathcal{O}(\\Delta t^6)\n",
    "\\end{align}\n",
    "\n",
    "The Dormand–Prince method employs a set of coefficients $a$, $b$, and $c$ to compute intermediate stages and combine them into higher and lower-order solutions.\n",
    "Below are the coefficients for the DP method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    [],\n",
    "    [1/5],\n",
    "    [3/40, 9/40],\n",
    "    [44/45, -56/15, 32/9],\n",
    "    [19372/6561, -25360/2187, 64448/6561, -212/729],\n",
    "    [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656],\n",
    "    [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84],\n",
    "]\n",
    "\n",
    "b_high = [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0] # Fifth-order accurate solution estimate\n",
    "b_low  = [5179/57600, 0, 7571/16695, 393/640, -92097/339200, 187/2100, 1/40] # Fourth-order accurate solution estimate\n",
    "\n",
    "c = [0, 1/5, 3/10, 4/5, 8/9, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "A DP45 step is therefore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP45_step(f, x, t, dt):\n",
    "        # Compute intermediate k1 to k7\n",
    "    k1 = np.array(f(*x))\n",
    "    k2 = np.array(f(*(x + dt*(a[1][0]*k1))))\n",
    "    k3 = np.array(f(*(x + dt*(a[2][0]*k1 + a[2][1]*k2))))\n",
    "    k4 = np.array(f(*(x + dt*(a[3][0]*k1 + a[3][1]*k2 + a[3][2]*k3))))\n",
    "    k5 = np.array(f(*(x + dt*(a[4][0]*k1 + a[4][1]*k2 + a[4][2]*k3 + a[4][3]*k4))))\n",
    "    k6 = np.array(f(*(x + dt*(a[5][0]*k1 + a[5][1]*k2 + a[5][2]*k3 + a[5][3]*k4 + a[5][4]*k5))))\n",
    "    k7 = np.array(f(*(x + dt*(a[6][0]*k1 + a[6][1]*k2 + a[6][2]*k3 + a[6][3]*k4 + a[6][4]*k5 + a[6][5]*k6))))\n",
    "\n",
    "    ks = [k1, k2, k3, k4, k5, k6, k7]\n",
    "\n",
    "    # Compute high and low order estimates\n",
    "    x_high = x + dt * np.dot(b_high, ks)\n",
    "    x_low  = x + dt * np.dot(b_low,  ks)\n",
    "\n",
    "    return x_high, x_low, ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Proportional-Integral Step Size Control\n",
    "\n",
    "Once we have an embedded Runge-Kutta method like Dormand–Prince in place, the next step is to implement a mechanism to adjust the step size based on the estimated local error.\n",
    "The PI (Proportional-Integral) controller is a widely-used strategy for this purpose, combining proportional and integral components to achieve stable and efficient step size adjustments.\n",
    "\n",
    "The PI controller adjusts the step size $\\Delta t$ based on the current error $E$ and past errors.\n",
    "The objective is to maintain the error within specified tolerances while preventing drastic changes in step size that could lead to instability or inefficiency.\n",
    "\n",
    "The general formula for updating the step size is:\n",
    "\\begin{align}\n",
    "h_{\\text{new}} = h \\cdot \\min\\left(\\text{fac}{\\text{max}}, \\max\\left(\\text{fac}{\\text{min}}, \\text{fac} \\cdot \\left(\\frac{\\text{tol}}{E}\\right)^{\\alpha}\\right)\\right)\n",
    "\\end{align}\n",
    "where $\\text{fac}$ is a scaling factor (typically around 0.9) to provide a safety margin;\n",
    "$\\text{fac}{\\text{min}}$ and $\\text{fac}{\\text{max}}$ set the minimum and maximum allowable step size multipliers to prevent excessive changes; and\n",
    "$\\alpha$ is an exponent that determines the responsiveness of the step size adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_update(dt, error, tol, fac=0.9, fac_min=0.1, fac_max=4.0, alpha=0.2):\n",
    "    if error == 0:\n",
    "        s = fac_max\n",
    "    else:\n",
    "        s = fac * (tol / error) ** alpha\n",
    "    s = min(fac_max, max(fac_min, s))\n",
    "    dt_new = dt * s\n",
    "    return dt_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Combining the single embedded step and the step controller, we obtain the DP45 algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP45(f, x, t, T, dt, atol, rtol):\n",
    "\n",
    "    Ts = [t]\n",
    "    Xs = [np.array(x)]\n",
    "\n",
    "    while t < T:\n",
    "        if t + dt > T:\n",
    "            dt = T - t  # Adjust step size to end exactly at tf\n",
    "\n",
    "        # Perform a single Dormand–Prince step\n",
    "        x_high, x_low, _ = DP45_step(f, x, t, dt)\n",
    "\n",
    "        # Compute the error estimate\n",
    "        error = np.linalg.norm(x_high - x_low, ord=np.inf)\n",
    "\n",
    "        # Compute the tolerance\n",
    "        tol = atol + rtol * np.linalg.norm(x_high, ord=np.inf)\n",
    "\n",
    "        # Check if the step is acceptable\n",
    "        if error <= tol:\n",
    "            # Accept the step\n",
    "            t += dt\n",
    "            x = x_high\n",
    "            Ts.append(t)\n",
    "            Xs.append(x)\n",
    "\n",
    "        # Compute the new step size\n",
    "        dt = dt_update(dt, error, tol)\n",
    "\n",
    "    return np.array(Ts), np.array(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can now apply it to the ODEs.\n",
    "\n",
    "Applying to the simple harmonic oscillator, we may specifically ask for the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sh(theta, omega):\n",
    "    return omega, -theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_DP45(tol):\n",
    "    T, X = DP45(f_sh, (0, 0.01), 0, 10, 0.1, tol, tol)\n",
    "    Theta  = X[:,0]\n",
    "    Thetap = 0.01 * np.sin(T)\n",
    "    return np.max(abs(Theta - Thetap))\n",
    "\n",
    "N     = np.array([64, 128, 256, 512, 1024])\n",
    "EDP45 = np.array([error_DP45(tol) for tol in 2.0**(-22-4*np.arange(5))])\n",
    "\n",
    "plt.loglog(N, 1/N**4,      label='1/N^4')\n",
    "plt.loglog(N, EDP45, 'o--', label='RK38')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(r'$\\text{err} = max|x_\\text{numeric} - x|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "For non-linear problems, we can compare different accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dp(th1, th2, p1, p2):\n",
    "    m  = 1\n",
    "    l  = 1\n",
    "    g  = 1\n",
    "\n",
    "    u1 = m * l * l\n",
    "    u2 = g / l\n",
    "    f  = 6 / (u1 * (16 - 9 * np.cos(th1 - th2)**2))\n",
    "\n",
    "    dth1 = f * (2 * p1 - 3 * np.cos(th1 - th2) * p2)\n",
    "    dth2 = f * (8 * p2 - 3 * np.cos(th1 - th2) * p1)\n",
    "\n",
    "    dp1  = - 0.5 * u1 * (  dth1 * dth2 * np.sin(th1 - th2) + 3 * u2 * np.sin(th1))\n",
    "    dp2  = - 0.5 * u1 * (- dth1 * dth2 * np.sin(th1 - th2) +     u2 * np.sin(th2))\n",
    "\n",
    "    return dth1, dth2, dp1, dp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, atol in enumerate([1e-3,1e-6,1e-9,1e-12]):\n",
    "    T, X = DP45(f_dp, (np.pi/2, np.pi/2, 0.0, 0.0), 0, 10, 0.1, atol, 0)\n",
    "    plt.plot(T[::10], X[::10,0], '.-',  color=f'C{i}', label=f'atol={atol}')\n",
    "    plt.plot(T[::10], X[::10,1], '.--', color=f'C{i}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Up to this point, we have explored the advanced concepts of Adaptive Step Size Control in Runge-Kutta methods, focusing on the Dormand–Prince (DP) method.\n",
    "We began by understanding the significance of embedded Runge-Kutta formulas, which enable simultaneous computation of solutions of different orders for effective error estimation.\n",
    "This foundation allowed us to implement a PI controller that dynamically adjusts the integration step size based on local error estimates, ensuring that the numerical solution remains within desired accuracy bounds while optimizing computational efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

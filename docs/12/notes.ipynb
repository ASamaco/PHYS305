{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Modeling II: Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Bayesian statistics systematically combines our prior knowledge about a situation with new data to refine what we believe is true.\n",
    "In countless real-world scenarios---ranging from medical diagnostics to fundamental physics experiments---information we already have (like the rarity of a disease or theoretical constraints on a physical parameter) can significantly shape how we interpret fresh evidence.\n",
    "By framing unknowns as probability distributions, Bayesian methods provide a coherent framework for updating those distributions whenever new observations appear, yielding a posterior that reflects all evidence, old and new.\n",
    "This unifying perspective makes it possible to quantify uncertainties in a transparent way, avoid common logical pitfalls, and naturally propagate errors to any derived quantities of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Medical Test \"Paradox\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The medical test paradox occurs when a diagnostic test is described as highly accurate, yet a person who tests positive for a rare disease ends up with a much lower chance of actually having it.\n",
    "This seemingly contradiction highlights the importance of prior knowledge or base rates.\n",
    "\n",
    "Consider a disease that affects only 1% of the population.\n",
    "Imagine a test that has:\n",
    "* 99% sensitivity: if you **do** have the disease, it flags you positive 99% of the time.\n",
    "* 99% specificity: if you **do not** have the disease, it correctly flags you negative 99% of the time.\n",
    "\n",
    "Many people assume that a \"99% accurate\" test implies a 99% chance of having the disease if you test positive.\n",
    "We will see that is not necessarily true when the disease is rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### A Simple Counting Argument\n",
    "\n",
    "Suppose we have 10,000 people.\n",
    "About 100 of them are diseased (1%).\n",
    "The remaining 9,900 are healthy.  \n",
    "\n",
    "Of the 100 diseased people, 99 will test positive (true positives).\n",
    "Of the 9,900 healthy people, 1% will falsely test positive (99 people).\n",
    "We end up with a total of 198 positive results: 99 true positives plus 99 false positives.\n",
    "\n",
    "Hence, only half of these positives (99 out of 198) are truly diseased.\n",
    "This implies a 50% chance of actually having the disease, which is far lower than 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Why This Happens\n",
    "\n",
    "When a condition is rare, most people do not have it.\n",
    "A small fraction of a large healthy group (the 1% false-positive rate applied to 9,900 healthy people) can match or exceed the positives from the much smaller diseased group.\n",
    "This is a direct consequence of prior probability: we have to weigh how common the disease is before we interpret a new test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## An Intuitive Derivation of Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem emerges directly from the definition of **conditional probability**.\n",
    "We start with $P(A \\mid B)$, which is read as \"the probability of $A$ given that $B$ occurred.\"\n",
    "By definition, this is the fraction of times both $A$ and $B$ happen, out of all times $B$ happens:\n",
    "\\begin{align}\n",
    "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Here, $P(A \\cap B)$ is the joint probability that both events occur.\n",
    "We can also express this joint probability in another way:\n",
    "\\begin{align}\n",
    "P(A \\cap B) = P(B \\mid A)\\,P(A).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Placing this back into our conditional probability formula gives:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can split $B$ into two disjoint groups:\n",
    "\\begin{align}\n",
    "P(B) = P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A}).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Putting this altogether yields **Bayes' Theorem**:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}\n",
    "       {P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can connect each term to our **medical test paradox**. In that story:\n",
    "* $P(A)$ is the **prevalence** (1%).\n",
    "* $P(\\bar{A})$ is the chance of not having the disease (99%).\n",
    "* $P(B \\mid A)$ is the **sensitivity** (99%).\n",
    "* $P(B \\mid \\bar{A})$ is the **false-positive rate** (1%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "When we substitute these numbers, we match the counting argument that led to a final probability of around 50% if you test positive.\n",
    "This result might seem surprising at first, but it follows naturally once we include both the **base rate** of the disease and the test's **accuracy**.\n",
    "Bayes' Theorem thus formalizes the intuition behind \"counting true positives vs. false positives\" and ensures we do not overlook the large fraction of healthy individuals in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "This same line of reasoning applies to many physics and data-modeling scenarios.\n",
    "We often start with a **prior** for a parameter (like the prevalence in the medical example) and then update it with **likelihood** information from new observations.\n",
    "Bayes' Theorem tells us how to combine both pieces of information in a consistent way, yielding a **posterior probability** that captures our updated understanding of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Why Bayes' Theorem Matters\n",
    "\n",
    "The key power of Bayes' Theorem is that it forces us to incorporate the **prior probability** $P(A)$ before we look at new evidence $B$.\n",
    "Once the data (test results) come in, we use the likelihood $P(B \\mid A)$ to update this prior, producing the **posterior probability** $P(A \\mid B)$.\n",
    "In the medical context, the \"update\" reveals how a single test result against a low prevalence might not be enough for a confident diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## A Physically Motivated Example: Exoplanet Detection\n",
    "\n",
    "We can adapt the logic from the medical test paradox to a physics or astronomy problem.\n",
    "Consider exoplanet detection: we look for a slight dip in a star's brightness that could signify a planet passing in front of the star (a \"transit\").\n",
    "Even if our detection algorithm is \"99% accurate,\" it may trigger many **false alarms** due to noise or stellar variability.\n",
    "If only a small fraction of stars have detectable planets, we face a scenario similar to the medical test paradox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup\n",
    "\n",
    "1. **Prevalence (Prior):** Suppose only **1%** of stars in our survey have a planet large enough (and orbit aligned just right) to cause a detectable transit.\n",
    "2. **Detection Sensitivity:** If a star truly has a planet, our detection pipeline correctly flags it **99%** of the time.\n",
    "3. **False Alarm Rate:** If a star does **not** have a planet, the pipeline still flags a **false positive** **1%** of the time (perhaps due to random noise, starspots, or measurement artifacts).\n",
    "\n",
    "These numbers mirror the \"disease prevalence\" and \"test sensitivity\" from the medical example.\n",
    "We want to know the **posterior probability** that a star truly has a planet given that we have detected a \"transit signal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Bayes' Theorem for Exoplanets\n",
    "\n",
    "Let:\n",
    "* $A$ = \"Star has a detectable planet.\"\n",
    "* $B$ = \"Detection algorithm flags a transit.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "By Bayes' Theorem,\n",
    "\\begin{align}\n",
    "P(\\text{Star has planet} \\,\\mid\\, \\text{Transit Flag}) =\n",
    "\\frac{P(\\text{Transit Flag} \\,\\mid\\, \\text{Star has planet}) \\times P(\\text{Star has planet})}{P(\\text{Transit Flag})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Here:\n",
    "1. $P(\\text{Star has planet})$ is the 1% prevalence (prior).\n",
    "2. $P(\\text{Transit Flag} \\,\\mid\\, \\text{Star has planet})$ is the 99% detection sensitivity.\n",
    "3. $P(\\text{Transit Flag})$ accounts for both real transits and false alarms.\n",
    "\n",
    "Just like in the medical paradox, we expect the **posterior probability** of having a planet given a positive detection to be around **50%**, not 99%. The rarity (1% prevalence) dilutes the significance of a single positive detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Python Demo: Simulating an Exoplanet Survey\n",
    "\n",
    "Below is a small Python script that simulates a survey of stars to illustrate how \"99% detection accuracy\" can still yield a large fraction of false positives if planets are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stars in the survey\n",
    "N_stars = 100_000\n",
    "\n",
    "# Prior: fraction of stars with a detectably transiting planet\n",
    "planet_prevalence = 0.01\n",
    "\n",
    "# Detection sensitivity: P(flagged transit | planet)\n",
    "detection_sensitivity = 0.99\n",
    "\n",
    "# False alarm rate: P(flagged transit | no planet) = 1 - specificity\n",
    "false_alarm_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# Simulate which stars have planets\n",
    "stars_have_planet = [\n",
    "    random() < planet_prevalence\n",
    "    for _ in range(N_stars)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate detection outcomes\n",
    "flags = []\n",
    "for has_planet in stars_have_planet:\n",
    "    if has_planet:\n",
    "        # Real transit flagged with probability = detection_sensitivity\n",
    "        flag = random() < detection_sensitivity\n",
    "    else:\n",
    "        # False alarm with probability = false_alarm_rate\n",
    "        flag = random() < false_alarm_rate\n",
    "    flags.append(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many flagged\n",
    "flagged_count = sum(flags)\n",
    "\n",
    "# Count how many flagged stars actually have planets\n",
    "true_planet_count = sum(\n",
    "    has_planet and flagged \n",
    "    for has_planet, flagged in zip(stars_have_planet, flags)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Out of {N_stars} stars, {flagged_count} were flagged.\")\n",
    "if flagged_count > 0:\n",
    "    posterior_prob = true_planet_count / flagged_count\n",
    "    print(f\"Among flagged stars, {true_planet_count} truly have planets.\")\n",
    "    print(f\"Posterior probability of having a planet if flagged: \"\n",
    "          f\"{posterior_prob:.2f}\")\n",
    "else:\n",
    "    print(\"No transits flagged (very unlikely with these settings)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "Adjust the different parameters and check if the results follow your intuition.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Example: Estimating the Mass of a New Fundamental Particle\n",
    "\n",
    "In high-energy physics, discovering or characterizing a new particle often boils down to measuring its mass (alongside other properties like spin or decay channels).\n",
    "Particle masses are typically extracted from observed signatures in a detector, such as energy peaks or invariant-mass distributions of decay products.\n",
    "Bayesian methods are increasingly used to combine \"priors\" (e.g., theoretical constraints, previous measurments) with \"likelihood\" (collision data) to infer a posterior distribution for the unknown mass.\n",
    "\n",
    "Below is a simplified illustration that mirrors our earlier continuous examples but sets the context in particle physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Physical Picture\n",
    "\n",
    "Suppose theorists predict a new fundamental particle with a mass in the range of 2 to 5 TeV.\n",
    "We carry out an experiment in a large collider and measure an invariant mass peak from the particle's decay products.\n",
    "However, our measurement is noisy and uncertain due to detector resolution, background events, etc.\n",
    "Let:\n",
    "* $\\theta$ = the particle's true mass (in TeV).  \n",
    "* $m_{\\text{obs}}$ = the observed peak from our measurement (in TeV).  \n",
    "\n",
    "We assume a **Gaussian** error model for simplicity:\n",
    "\\begin{align}\n",
    "m_{\\text{obs}} \\sim \\mathcal{N}(\\theta, \\sigma^2),\n",
    "\\end{align}\n",
    "where $\\sigma$ represents the *typical detector resolution* or *statistical uncertainty* in reconstructing the mass peak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Prior on the Particle's Mass\n",
    "\n",
    "We might have a **theoretical prior** stating that $\\theta$ lies between 2 and 5 TeV, with no strong preference within that range.\n",
    "That leads to a **uniform prior**:\n",
    "\\begin{align}\n",
    "p(\\theta) = \n",
    "\\begin{cases}\n",
    "\\frac{1}{5 - 2}, & 2 \\le \\theta \\le 5, \\\\\n",
    "0, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "In a real analysis, the prior might come from previous measurements/constraints like electroweak measurements or indirect searches, but a uniform prior is a straightforward starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Likelihood of Observed Data\n",
    "\n",
    "If the measured peak is $m_\\text{obs}=3.2$ TeV with an uncertainty $\\sigma=0.2$ TeV, the **likelihood** function is:\n",
    "\\begin{align}\n",
    "p(m_{\\text{obs}} \\mid \\theta) \n",
    "= \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\n",
    "  \\exp\\left[-\\frac{(m_{\\text{obs}}-\\theta)^2}{2\\sigma^2}\\right].\n",
    "\\end{align}\n",
    "\n",
    "This function is large if $\\theta$ is near 3.2 TeV and small if $\\theta$ is far from 3.2 TeV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Posterior Distribution\n",
    "\n",
    "Bayes' Theorem states:\n",
    "\\begin{align}\n",
    "p(\\theta \\mid m_{\\text{obs}}) \n",
    "\\propto p(m_{\\text{obs}} \\mid \\theta) \\, p(\\theta).\n",
    "\\end{align}\n",
    "\n",
    "We then normalize the right-hand side to ensure the posterior integrates to 1 over $\\theta \\in [2,5]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Python Demo: Simple Grid Approximation\n",
    "\n",
    "Below is a small Python code that illustrates how to compute the posterior distribution by sampling $\\theta$ on a grid from 2 to 5 TeV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed mass peak (TeV) and estimated detector resolution (TeV)\n",
    "m_obs = 3.2\n",
    "sigma = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range for theta (2 to 5 TeV)\n",
    "\n",
    "theta_min, theta_max = 2.0, 5.0\n",
    "n_points = 3000\n",
    "thetas = np.linspace(theta_min, theta_max, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform prior in [2, 5]\n",
    "def prior(theta):\n",
    "    # 1/(5-2)=1/3 in [2,5], else 0\n",
    "    return np.where((theta >= theta_min) & (theta <= theta_max), 1/(theta_max - theta_min), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian likelihood\n",
    "def likelihood(m_obs, theta, sigma):\n",
    "    norm = 1.0 / (np.sqrt(2*np.pi) * sigma)\n",
    "    return norm * np.exp(- 0.5 * ((m_obs - theta)/sigma)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unnormalized posterior\n",
    "unnorm_post = likelihood(m_obs, thetas, sigma) * prior(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "norm = np.trapezoid(unnorm_post, thetas)\n",
    "post = unnorm_post / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior\n",
    "\n",
    "plt.plot(thetas, post, color='k', label=\"Posterior PDF\")\n",
    "plt.axvline(m_obs, ls='--', label=f\"Observed peak={m_obs} TeV\")\n",
    "plt.title(\"Posterior for New Particle Mass\")\n",
    "plt.xlabel(\"Mass (TeV)\")\n",
    "plt.ylabel(\"Posterior Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "When you run this script, you see a posterior distribution peaked near 3.2 TeV.\n",
    "The width of the posterior depends on $\\sigma$ and how close 3.2 TeV is to the edges (2 or 5 TeV).\n",
    "If the measured value were near the boundary (e.g., 2.1 TeV), the posterior might be truncated heavily on one side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "In this simplified scenario:\n",
    "1. The prior indicates that $\\theta$ should lie somewhere between 2 and 5 TeV.\n",
    "2. The likelihood becomes sharper if our detector resolution is good (small $\\sigma$).\n",
    "3. The posterior is effectively a constrained, \"truncated\" Gaussian centered near the observed peak, but strictly between 2 and 5 TeV.\n",
    "\n",
    "In reality, measuring a new particle mass at a collider typically involves many events rather than a single measurement.\n",
    "We would accumulate data from multiple collisions, each with some measured mass or energy distribution.\n",
    "The Bayesian approach, however, remains the same: start with a prior (theoretical constraints), define the likelihood (the probability of observing the data given a hypothesized mass), and compute the posterior distribution over $\\theta$.\n",
    "(See the lab.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "Adjust the different parameters and check if the results follow your intuition.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

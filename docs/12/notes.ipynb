{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Modeling II: Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Bayesian statistics systematically combines our prior knowledge about a situation with new data to refine what we believe is true.\n",
    "In countless real-world scenarios---ranging from medical diagnostics to fundamental physics experiments---information we already have (like the rarity of a disease or theoretical constraints on a physical parameter) can significantly shape how we interpret fresh evidence.\n",
    "By framing unknowns as probability distributions, Bayesian methods provide a coherent framework for updating those distributions whenever new observations appear, yielding a posterior that reflects all evidence, old and new.\n",
    "This unifying perspective makes it possible to quantify uncertainties in a transparent way, avoid common logical pitfalls, and naturally propagate errors to any derived quantities of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Medical Test \"Paradox\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The medical test paradox occurs when a diagnostic test is described as highly accurate, yet a person who tests positive for a rare disease ends up with a much lower chance of actually having it.\n",
    "This seemingly contradiction highlights the importance of prior knowledge or base rates.\n",
    "\n",
    "Consider a disease that affects only 1% of the population.\n",
    "Imagine a test that has:\n",
    "* 99% sensitivity: if you **do** have the disease, it flags you positive 99% of the time.\n",
    "* 99% specificity: if you **do not** have the disease, it correctly flags you negative 99% of the time.\n",
    "\n",
    "Many people assume that a \"99% accurate\" test implies a 99% chance of having the disease if you test positive.\n",
    "We will see that is not necessarily true when the disease is rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### A Simple Counting Argument\n",
    "\n",
    "Suppose we have 10,000 people.\n",
    "About 100 of them are diseased (1%).\n",
    "The remaining 9,900 are healthy.  \n",
    "\n",
    "Of the 100 diseased people, 99 will test positive (true positives).\n",
    "Of the 9,900 healthy people, 1% will falsely test positive (99 people).\n",
    "We end up with a total of 198 positive results: 99 true positives plus 99 false positives.\n",
    "\n",
    "Hence, only half of these positives (99 out of 198) are truly diseased.\n",
    "This implies a 50% chance of actually having the disease, which is far lower than 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Why This Happens\n",
    "\n",
    "When a condition is rare, most people do not have it.\n",
    "A small fraction of a large healthy group (the 1% false-positive rate applied to 9,900 healthy people) can match or exceed the positives from the much smaller diseased group.\n",
    "This is a direct consequence of prior probability: we have to weigh how common the disease is before we interpret a new test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## An Intuitive Derivation of Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem emerges directly from the definition of **conditional probability**.\n",
    "We start with $P(A \\mid B)$, which is read as \"the probability of $A$ given that $B$ occurred.\"\n",
    "By definition, this is the fraction of times both $A$ and $B$ happen, out of all times $B$ happens:\n",
    "\\begin{align}\n",
    "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Here, $P(A \\cap B)$ is the joint probability that both events occur.\n",
    "We can also express this joint probability in another way:\n",
    "\\begin{align}\n",
    "P(A \\cap B) = P(B \\mid A)\\,P(A).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Placing this back into our conditional probability formula gives:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can split $B$ into two disjoint groups:\n",
    "\\begin{align}\n",
    "P(B) = P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A}).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Putting this altogether yields **Bayes' Theorem**:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}\n",
    "       {P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can connect each term to our **medical test paradox**. In that story:\n",
    "* $P(A)$ is the **prevalence** (1%).\n",
    "* $P(\\bar{A})$ is the chance of not having the disease (99%).\n",
    "* $P(B \\mid A)$ is the **sensitivity** (99%).\n",
    "* $P(B \\mid \\bar{A})$ is the **false-positive rate** (1%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "When we substitute these numbers, we match the counting argument that led to a final probability of around 50% if you test positive.\n",
    "This result might seem surprising at first, but it follows naturally once we include both the **base rate** of the disease and the test's **accuracy**.\n",
    "Bayes' Theorem thus formalizes the intuition behind \"counting true positives vs. false positives\" and ensures we do not overlook the large fraction of healthy individuals in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "This same line of reasoning applies to many physics and data-modeling scenarios.\n",
    "We often start with a **prior** for a parameter (like the prevalence in the medical example) and then update it with **likelihood** information from new observations.\n",
    "Bayes' Theorem tells us how to combine both pieces of information in a consistent way, yielding a **posterior probability** that captures our updated understanding of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Why Bayes' Theorem Matters\n",
    "\n",
    "The key power of Bayes' Theorem is that it forces us to incorporate the **prior probability** $P(A)$ before we look at new evidence $B$.\n",
    "Once the data (test results) come in, we use the likelihood $P(B \\mid A)$ to update this prior, producing the **posterior probability** $P(A \\mid B)$.\n",
    "In the medical context, the \"update\" reveals how a single test result against a low prevalence might not be enough for a confident diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## A Physically Motivated Example: Exoplanet Detection\n",
    "\n",
    "We can adapt the logic from the medical test paradox to a physics or astronomy problem.\n",
    "Consider exoplanet detection: we look for a slight dip in a star's brightness that could signify a planet passing in front of the star (a \"transit\").\n",
    "Even if our detection algorithm is \"99% accurate,\" it may trigger many **false alarms** due to noise or stellar variability.\n",
    "If only a small fraction of stars have detectable planets, we face a scenario similar to the medical test paradox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup\n",
    "\n",
    "1. **Prevalence (Prior):** Suppose only **1%** of stars in our survey have a planet large enough (and orbit aligned just right) to cause a detectable transit.\n",
    "2. **Detection Sensitivity:** If a star truly has a planet, our detection pipeline correctly flags it **99%** of the time.\n",
    "3. **False Alarm Rate:** If a star does **not** have a planet, the pipeline still flags a **false positive** **1%** of the time (perhaps due to random noise, starspots, or measurement artifacts).\n",
    "\n",
    "These numbers mirror the \"disease prevalence\" and \"test sensitivity\" from the medical example.\n",
    "We want to know the **posterior probability** that a star truly has a planet given that we have detected a \"transit signal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Bayes' Theorem for Exoplanets\n",
    "\n",
    "Let:\n",
    "* $A$ = \"Star has a detectable planet.\"\n",
    "* $B$ = \"Detection algorithm flags a transit.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "By Bayes' Theorem,\n",
    "\\begin{align}\n",
    "P(\\text{Star has planet} \\,\\mid\\, \\text{Transit Flag}) =\n",
    "\\frac{P(\\text{Transit Flag} \\,\\mid\\, \\text{Star has planet}) \\times P(\\text{Star has planet})}{P(\\text{Transit Flag})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Here:\n",
    "1. $P(\\text{Star has planet})$ is the 1% prevalence (prior).\n",
    "2. $P(\\text{Transit Flag} \\,\\mid\\, \\text{Star has planet})$ is the 99% detection sensitivity.\n",
    "3. $P(\\text{Transit Flag})$ accounts for both real transits and false alarms.\n",
    "\n",
    "Just like in the medical paradox, we expect the **posterior probability** of having a planet given a positive detection to be around **50%**, not 99%. The rarity (1% prevalence) dilutes the significance of a single positive detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Python Demo: Simulating an Exoplanet Survey\n",
    "\n",
    "Below is a small Python script that simulates a survey of stars to illustrate how \"99% detection accuracy\" can still yield a large fraction of false positives if planets are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stars in the survey\n",
    "N_stars = 100_000\n",
    "\n",
    "# Prior: fraction of stars with a detectably transiting planet\n",
    "planet_prevalence = 0.01\n",
    "\n",
    "# Detection sensitivity: P(flagged transit | planet)\n",
    "detection_sensitivity = 0.99\n",
    "\n",
    "# False alarm rate: P(flagged transit | no planet) = 1 - specificity\n",
    "false_alarm_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# Simulate which stars have planets\n",
    "stars_have_planet = [\n",
    "    random() < planet_prevalence\n",
    "    for _ in range(N_stars)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate detection outcomes\n",
    "flags = []\n",
    "for has_planet in stars_have_planet:\n",
    "    if has_planet:\n",
    "        # Real transit flagged with probability = detection_sensitivity\n",
    "        flag = random() < detection_sensitivity\n",
    "    else:\n",
    "        # False alarm with probability = false_alarm_rate\n",
    "        flag = random() < false_alarm_rate\n",
    "    flags.append(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many flagged\n",
    "flagged_count = sum(flags)\n",
    "\n",
    "# Count how many flagged stars actually have planets\n",
    "true_planet_count = sum(\n",
    "    has_planet and flagged \n",
    "    for has_planet, flagged in zip(stars_have_planet, flags)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Out of {N_stars} stars, {flagged_count} were flagged.\")\n",
    "if flagged_count > 0:\n",
    "    posterior_prob = true_planet_count / flagged_count\n",
    "    print(f\"Among flagged stars, {true_planet_count} truly have planets.\")\n",
    "    print(f\"Posterior probability of having a planet if flagged: \"\n",
    "          f\"{posterior_prob:.2f}\")\n",
    "else:\n",
    "    print(\"No transits flagged (very unlikely with these settings)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "Adjust the different parameters and check if the results follow your intuition.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

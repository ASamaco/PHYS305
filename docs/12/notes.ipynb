{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Modeling II: Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Bayesian statistics systematically combines our prior knowledge about a situation with new data to refine what we believe is true.\n",
    "In countless real-world scenarios---ranging from medical diagnostics to fundamental physics experiments---information we already have (like the rarity of a disease or theoretical constraints on a physical parameter) can significantly shape how we interpret fresh evidence.\n",
    "By framing unknowns as probability distributions, Bayesian methods provide a coherent framework for updating those distributions whenever new observations appear, yielding a posterior that reflects all evidence, old and new.\n",
    "This unifying perspective makes it possible to quantify uncertainties in a transparent way, avoid common logical pitfalls, and naturally propagate errors to any derived quantities of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Medical Test \"Paradox\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The medical test paradox occurs when a diagnostic test is described as highly accurate, yet a person who tests positive for a rare disease ends up with a much lower chance of actually having it.\n",
    "This seemingly contradiction highlights the importance of prior knowledge or base rates.\n",
    "\n",
    "Consider a disease that affects only 1% of the population.\n",
    "Imagine a test that has:\n",
    "* 99% sensitivity: if you **do** have the disease, it flags you positive 99% of the time.\n",
    "* 99% specificity: if you **do not** have the disease, it correctly flags you negative 99% of the time.\n",
    "\n",
    "Many people assume that a \"99% accurate\" test implies a 99% chance of having the disease if you test positive.\n",
    "We will see that is not necessarily true when the disease is rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### A Simple Counting Argument\n",
    "\n",
    "Suppose we have 10,000 people.\n",
    "About 100 of them are diseased (1%).\n",
    "The remaining 9,900 are healthy.  \n",
    "\n",
    "Of the 100 diseased people, 99 will test positive (true positives).\n",
    "Of the 9,900 healthy people, 1% will falsely test positive (99 people).\n",
    "We end up with a total of 198 positive results: 99 true positives plus 99 false positives.\n",
    "\n",
    "Hence, only half of these positives (99 out of 198) are truly diseased.\n",
    "This implies a 50% chance of actually having the disease, which is far lower than 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Why This Happens\n",
    "\n",
    "When a condition is rare, most people do not have it.\n",
    "A small fraction of a large healthy group (the 1% false-positive rate applied to 9,900 healthy people) can match or exceed the positives from the much smaller diseased group.\n",
    "This is a direct consequence of prior probability: we have to weigh how common the disease is before we interpret a new test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## An Intuitive Derivation of Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem emerges directly from the definition of **conditional probability**.\n",
    "We start with $P(A \\mid B)$, which is read as \"the probability of $A$ given that $B$ occurred.\"\n",
    "By definition, this is the fraction of times both $A$ and $B$ happen, out of all times $B$ happens:\n",
    "\\begin{align}\n",
    "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Here, $P(A \\cap B)$ is the joint probability that both events occur.\n",
    "We can also express this joint probability in another way:\n",
    "\\begin{align}\n",
    "P(A \\cap B) = P(B \\mid A)\\,P(A).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Placing this back into our conditional probability formula gives:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can split $B$ into two disjoint groups:\n",
    "\\begin{align}\n",
    "P(B) = P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A}).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Putting this altogether yields **Bayes' Theorem**:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}\n",
    "       {P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can connect each term to our **medical test paradox**. In that story:\n",
    "* $P(A)$ is the **prevalence** (1%).\n",
    "* $P(\\bar{A})$ is the chance of not having the disease (99%).\n",
    "* $P(B \\mid A)$ is the **sensitivity** (99%).\n",
    "* $P(B \\mid \\bar{A})$ is the **false-positive rate** (1%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "When we substitute these numbers, we match the counting argument that led to a final probability of around 50% if you test positive.\n",
    "This result might seem surprising at first, but it follows naturally once we include both the **base rate** of the disease and the test's **accuracy**.\n",
    "Bayes' Theorem thus formalizes the intuition behind \"counting true positives vs. false positives\" and ensures we do not overlook the large fraction of healthy individuals in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "This same line of reasoning applies to many physics and data-modeling scenarios.\n",
    "We often start with a **prior** for a parameter (like the prevalence in the medical example) and then update it with **likelihood** information from new observations.\n",
    "Bayes' Theorem tells us how to combine both pieces of information in a consistent way, yielding a **posterior probability** that captures our updated understanding of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Why Bayes' Theorem Matters\n",
    "\n",
    "The key power of Bayes' Theorem is that it forces us to incorporate the **prior probability** $P(A)$ before we look at new evidence $B$.\n",
    "Once the data (test results) come in, we use the likelihood $P(B \\mid A)$ to update this prior, producing the **posterior probability** $P(A \\mid B)$.\n",
    "In the medical context, the \"update\" reveals how a single test result against a low prevalence might not be enough for a confident diagnosis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
